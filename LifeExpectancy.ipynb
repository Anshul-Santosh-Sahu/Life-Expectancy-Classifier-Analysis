{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "354407d5-8d33-4563-b734-5be642e39552",
      "metadata": {
        "id": "354407d5-8d33-4563-b734-5be642e39552"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "120867d0-e8b3-4909-b443-d851e09415e3",
      "metadata": {
        "id": "120867d0-e8b3-4909-b443-d851e09415e3",
        "outputId": "ef6a5301-67e5-47d4-daf1-c431c67c2cc1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Country</th>\n",
              "      <th>Year</th>\n",
              "      <th>Status</th>\n",
              "      <th>Life expectancy</th>\n",
              "      <th>Adult Mortality</th>\n",
              "      <th>infant deaths</th>\n",
              "      <th>Alcohol</th>\n",
              "      <th>percentage expenditure</th>\n",
              "      <th>Hepatitis B</th>\n",
              "      <th>Measles</th>\n",
              "      <th>...</th>\n",
              "      <th>Polio</th>\n",
              "      <th>Total expenditure</th>\n",
              "      <th>Diphtheria</th>\n",
              "      <th>HIV/AIDS</th>\n",
              "      <th>GDP</th>\n",
              "      <th>Population</th>\n",
              "      <th>thinness  1-19 years</th>\n",
              "      <th>thinness 5-9 years</th>\n",
              "      <th>Income composition of resources</th>\n",
              "      <th>Schooling</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Afghanistan</td>\n",
              "      <td>2015</td>\n",
              "      <td>Developing</td>\n",
              "      <td>65.0</td>\n",
              "      <td>263.0</td>\n",
              "      <td>62</td>\n",
              "      <td>0.01</td>\n",
              "      <td>71.279624</td>\n",
              "      <td>65.0</td>\n",
              "      <td>1154</td>\n",
              "      <td>...</td>\n",
              "      <td>6.0</td>\n",
              "      <td>8.16</td>\n",
              "      <td>65.0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>584.259210</td>\n",
              "      <td>33736494.0</td>\n",
              "      <td>17.2</td>\n",
              "      <td>17.3</td>\n",
              "      <td>0.479</td>\n",
              "      <td>10.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Afghanistan</td>\n",
              "      <td>2014</td>\n",
              "      <td>Developing</td>\n",
              "      <td>59.9</td>\n",
              "      <td>271.0</td>\n",
              "      <td>64</td>\n",
              "      <td>0.01</td>\n",
              "      <td>73.523582</td>\n",
              "      <td>62.0</td>\n",
              "      <td>492</td>\n",
              "      <td>...</td>\n",
              "      <td>58.0</td>\n",
              "      <td>8.18</td>\n",
              "      <td>62.0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>612.696514</td>\n",
              "      <td>327582.0</td>\n",
              "      <td>17.5</td>\n",
              "      <td>17.5</td>\n",
              "      <td>0.476</td>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Afghanistan</td>\n",
              "      <td>2013</td>\n",
              "      <td>Developing</td>\n",
              "      <td>59.9</td>\n",
              "      <td>268.0</td>\n",
              "      <td>66</td>\n",
              "      <td>0.01</td>\n",
              "      <td>73.219243</td>\n",
              "      <td>64.0</td>\n",
              "      <td>430</td>\n",
              "      <td>...</td>\n",
              "      <td>62.0</td>\n",
              "      <td>8.13</td>\n",
              "      <td>64.0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>631.744976</td>\n",
              "      <td>31731688.0</td>\n",
              "      <td>17.7</td>\n",
              "      <td>17.7</td>\n",
              "      <td>0.470</td>\n",
              "      <td>9.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Afghanistan</td>\n",
              "      <td>2012</td>\n",
              "      <td>Developing</td>\n",
              "      <td>59.5</td>\n",
              "      <td>272.0</td>\n",
              "      <td>69</td>\n",
              "      <td>0.01</td>\n",
              "      <td>78.184215</td>\n",
              "      <td>67.0</td>\n",
              "      <td>2787</td>\n",
              "      <td>...</td>\n",
              "      <td>67.0</td>\n",
              "      <td>8.52</td>\n",
              "      <td>67.0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>669.959000</td>\n",
              "      <td>3696958.0</td>\n",
              "      <td>17.9</td>\n",
              "      <td>18.0</td>\n",
              "      <td>0.463</td>\n",
              "      <td>9.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Afghanistan</td>\n",
              "      <td>2011</td>\n",
              "      <td>Developing</td>\n",
              "      <td>59.2</td>\n",
              "      <td>275.0</td>\n",
              "      <td>71</td>\n",
              "      <td>0.01</td>\n",
              "      <td>7.097109</td>\n",
              "      <td>68.0</td>\n",
              "      <td>3013</td>\n",
              "      <td>...</td>\n",
              "      <td>68.0</td>\n",
              "      <td>7.87</td>\n",
              "      <td>68.0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>63.537231</td>\n",
              "      <td>2978599.0</td>\n",
              "      <td>18.2</td>\n",
              "      <td>18.2</td>\n",
              "      <td>0.454</td>\n",
              "      <td>9.5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 22 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Country  Year      Status  Life expectancy   Adult Mortality  \\\n",
              "0  Afghanistan  2015  Developing              65.0            263.0   \n",
              "1  Afghanistan  2014  Developing              59.9            271.0   \n",
              "2  Afghanistan  2013  Developing              59.9            268.0   \n",
              "3  Afghanistan  2012  Developing              59.5            272.0   \n",
              "4  Afghanistan  2011  Developing              59.2            275.0   \n",
              "\n",
              "   infant deaths  Alcohol  percentage expenditure  Hepatitis B  Measles   ...  \\\n",
              "0             62     0.01               71.279624         65.0      1154  ...   \n",
              "1             64     0.01               73.523582         62.0       492  ...   \n",
              "2             66     0.01               73.219243         64.0       430  ...   \n",
              "3             69     0.01               78.184215         67.0      2787  ...   \n",
              "4             71     0.01                7.097109         68.0      3013  ...   \n",
              "\n",
              "   Polio  Total expenditure  Diphtheria    HIV/AIDS         GDP  Population  \\\n",
              "0    6.0               8.16         65.0        0.1  584.259210  33736494.0   \n",
              "1   58.0               8.18         62.0        0.1  612.696514    327582.0   \n",
              "2   62.0               8.13         64.0        0.1  631.744976  31731688.0   \n",
              "3   67.0               8.52         67.0        0.1  669.959000   3696958.0   \n",
              "4   68.0               7.87         68.0        0.1   63.537231   2978599.0   \n",
              "\n",
              "    thinness  1-19 years   thinness 5-9 years  \\\n",
              "0                   17.2                 17.3   \n",
              "1                   17.5                 17.5   \n",
              "2                   17.7                 17.7   \n",
              "3                   17.9                 18.0   \n",
              "4                   18.2                 18.2   \n",
              "\n",
              "   Income composition of resources  Schooling  \n",
              "0                            0.479       10.1  \n",
              "1                            0.476       10.0  \n",
              "2                            0.470        9.9  \n",
              "3                            0.463        9.8  \n",
              "4                            0.454        9.5  \n",
              "\n",
              "[5 rows x 22 columns]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv(r\"Life Expectancy Data.csv\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "880b484f-0636-49a6-acf1-44a20c20acb7",
      "metadata": {
        "id": "880b484f-0636-49a6-acf1-44a20c20acb7"
      },
      "outputs": [],
      "source": [
        "# Instead of using inplace=True, assign back to the column directly\n",
        "df['Year'] = df['Year'].fillna(df['Year'].median())\n",
        "df['Schooling'] = df['Schooling'].fillna(df['Schooling'].mode()[0])\n",
        "\n",
        "# Dropping the 'Status' column\n",
        "df.drop('Status', axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a28bb7c-4489-45ba-8a97-cff2a1fa9102",
      "metadata": {
        "id": "7a28bb7c-4489-45ba-8a97-cff2a1fa9102"
      },
      "outputs": [],
      "source": [
        "label_enc = LabelEncoder()\n",
        "df['Country'] = label_enc.fit_transform(df['Country'])\n",
        "df['Schooling'] = label_enc.fit_transform(df['Schooling'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f442b18-7a26-40b4-9589-1030a6fb3c47",
      "metadata": {
        "id": "0f442b18-7a26-40b4-9589-1030a6fb3c47",
        "outputId": "0a9cbd33-650b-494d-fc41-9bfeb89fa796"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index(['Country', 'Year', 'Life expectancy ', 'Adult Mortality',\n",
            "       'infant deaths', 'Alcohol', 'percentage expenditure', 'Hepatitis B',\n",
            "       'Measles ', ' BMI ', 'under-five deaths ', 'Polio', 'Total expenditure',\n",
            "       'Diphtheria ', ' HIV/AIDS', 'GDP', 'Population',\n",
            "       ' thinness  1-19 years', ' thinness 5-9 years',\n",
            "       'Income composition of resources', 'Schooling'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "print(df.columns)\n",
        "\n",
        "X = df.drop('Life expectancy ', axis=1)\n",
        "\n",
        "y = df['Country']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dbfd3d64-bffa-4554-9519-b7b5db0f71ea",
      "metadata": {
        "id": "dbfd3d64-bffa-4554-9519-b7b5db0f71ea"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50126e6b-a0fd-4709-946d-77155e7ff2f9",
      "metadata": {
        "id": "50126e6b-a0fd-4709-946d-77155e7ff2f9"
      },
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "851b0dfd-7387-4bb4-b0c3-5192cbb6ffcb",
      "metadata": {
        "id": "851b0dfd-7387-4bb4-b0c3-5192cbb6ffcb"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(y_true, y_pred, model_name):\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    # Changed to use 'weighted' averaging for multiclass\n",
        "    precision = precision_score(y_true, y_pred, average='weighted')\n",
        "    recall = recall_score(y_true, y_pred, average='weighted')\n",
        "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "    print(f'---{model_name}---')\n",
        "    print(f'Accuracy: {accuracy:.2f}')\n",
        "    print(f'Precision: {precision:.2f}')\n",
        "    print(f'Recall: {recall:.2f}')\n",
        "    print(f'F1 Score: {f1:.2f}')\n",
        "    print(f'Confusion Matrix:\\n{confusion_matrix(y_true, y_pred)}')\n",
        "    print('-'*40)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01ad9e0d-2887-4c61-a56b-3a8d9090de7a",
      "metadata": {
        "id": "01ad9e0d-2887-4c61-a56b-3a8d9090de7a"
      },
      "source": [
        "### 1. Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a3ce38e-4cfc-43bc-aa7b-e0ad9ea6981d",
      "metadata": {
        "id": "1a3ce38e-4cfc-43bc-aa7b-e0ad9ea6981d",
        "outputId": "4cb371a7-1adf-4a3e-99ce-b17401201eae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---Logistic Regression---\n",
            "Accuracy: 0.76\n",
            "Precision: 0.82\n",
            "Recall: 0.76\n",
            "F1 Score: 0.76\n",
            "Confusion Matrix:\n",
            "[[1 0 0 ... 0 0 0]\n",
            " [0 2 0 ... 0 0 0]\n",
            " [0 0 4 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 4 0 0]\n",
            " [0 0 0 ... 0 1 0]\n",
            " [0 0 0 ... 0 1 1]]\n",
            "----------------------------------------\n"
          ]
        }
      ],
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "\n",
        "X_train = imputer.fit_transform(X_train)\n",
        "X_test = imputer.transform(X_test)\n",
        "\n",
        "log_reg = LogisticRegression()\n",
        "log_reg.fit(X_train, y_train)\n",
        "y_pred_lr = log_reg.predict(X_test)\n",
        "evaluate_model(y_test, y_pred_lr, \"Logistic Regression\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bbf07c04-6fbb-41b8-9208-a81f8ac957ea",
      "metadata": {
        "id": "bbf07c04-6fbb-41b8-9208-a81f8ac957ea"
      },
      "source": [
        "### 2. Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d2ffe64-4d7c-462c-b63b-8232c22ec2e2",
      "metadata": {
        "id": "9d2ffe64-4d7c-462c-b63b-8232c22ec2e2",
        "outputId": "78dfb566-86bd-44b5-d919-9d201eb8c66d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---Naive Bayes---\n",
            "Accuracy: 0.99\n",
            "Precision: 0.99\n",
            "Recall: 0.99\n",
            "F1 Score: 0.99\n",
            "Confusion Matrix:\n",
            "[[1 0 0 ... 0 0 0]\n",
            " [0 2 0 ... 0 0 0]\n",
            " [0 0 4 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 4 0 0]\n",
            " [0 0 0 ... 0 1 0]\n",
            " [0 0 0 ... 0 0 3]]\n",
            "----------------------------------------\n"
          ]
        }
      ],
      "source": [
        "nb_model = GaussianNB()\n",
        "nb_model.fit(X_train, y_train)\n",
        "y_pred_nb = nb_model.predict(X_test)\n",
        "evaluate_model(y_test, y_pred_nb, \"Naive Bayes\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "86dd60e1-c249-44f4-921d-f475efd59605",
      "metadata": {
        "id": "86dd60e1-c249-44f4-921d-f475efd59605"
      },
      "source": [
        "### 3. K-Nearest Neighbors (KNN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ac510b6-f530-4e3a-9b81-5b5a208febca",
      "metadata": {
        "id": "9ac510b6-f530-4e3a-9b81-5b5a208febca",
        "outputId": "153879c9-ea69-4e6c-ab46-492c81fda463"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---K-Nearest Neighbors---\n",
            "Accuracy: 0.62\n",
            "Precision: 0.69\n",
            "Recall: 0.62\n",
            "F1 Score: 0.62\n",
            "Confusion Matrix:\n",
            "[[1 0 0 ... 0 0 0]\n",
            " [0 2 0 ... 0 0 0]\n",
            " [0 0 4 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 4 0 0]\n",
            " [0 0 0 ... 0 1 0]\n",
            " [0 0 0 ... 0 1 0]]\n",
            "----------------------------------------\n"
          ]
        }
      ],
      "source": [
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "knn.fit(X_train, y_train)\n",
        "y_pred_knn = knn.predict(X_test)\n",
        "evaluate_model(y_test, y_pred_knn, \"K-Nearest Neighbors\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "956c8f15-7128-4d79-8772-66ad0408ed70",
      "metadata": {
        "id": "956c8f15-7128-4d79-8772-66ad0408ed70"
      },
      "source": [
        "### 4. Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5714f2f-2533-4495-bbf5-1e5ceb93e209",
      "metadata": {
        "id": "e5714f2f-2533-4495-bbf5-1e5ceb93e209",
        "outputId": "27f9a7f3-539c-4b8d-aa0d-0ab9596a74b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---Decision Tree---\n",
            "Accuracy: 0.98\n",
            "Precision: 0.98\n",
            "Recall: 0.98\n",
            "F1 Score: 0.97\n",
            "Confusion Matrix:\n",
            "[[1 0 0 ... 0 0 0]\n",
            " [0 2 0 ... 0 0 0]\n",
            " [0 0 4 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 4 0 0]\n",
            " [0 0 0 ... 0 1 0]\n",
            " [0 0 0 ... 0 0 3]]\n",
            "----------------------------------------\n"
          ]
        }
      ],
      "source": [
        "dt_model = DecisionTreeClassifier(random_state=42)\n",
        "dt_model.fit(X_train, y_train)\n",
        "y_pred_dt = dt_model.predict(X_test)\n",
        "evaluate_model(y_test, y_pred_dt, \"Decision Tree\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8146474d-143c-43fa-9ac8-35fcb9ee001f",
      "metadata": {
        "id": "8146474d-143c-43fa-9ac8-35fcb9ee001f"
      },
      "source": [
        "### 5. Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5733db2f-6b60-40bb-ad3b-d8456dd78cb2",
      "metadata": {
        "id": "5733db2f-6b60-40bb-ad3b-d8456dd78cb2",
        "outputId": "52748e64-1350-4a0b-8010-307b10c2f9dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---Random Forest---\n",
            "Accuracy: 0.99\n",
            "Precision: 0.99\n",
            "Recall: 0.99\n",
            "F1 Score: 0.99\n",
            "Confusion Matrix:\n",
            "[[1 0 0 ... 0 0 0]\n",
            " [0 2 0 ... 0 0 0]\n",
            " [0 0 4 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 4 0 0]\n",
            " [0 0 0 ... 0 1 0]\n",
            " [0 0 0 ... 0 0 3]]\n",
            "----------------------------------------\n"
          ]
        }
      ],
      "source": [
        "rf_model = RandomForestClassifier(random_state=42, n_estimators=100)\n",
        "rf_model.fit(X_train, y_train)\n",
        "y_pred_rf = rf_model.predict(X_test)\n",
        "evaluate_model(y_test, y_pred_rf, \"Random Forest\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0616cd5b-da67-4598-9585-f6828190bf8d",
      "metadata": {
        "id": "0616cd5b-da67-4598-9585-f6828190bf8d"
      },
      "source": [
        "### 6. KMeans (Unsupervised Clustering) for analysis, not classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "155efa59-4012-45de-ac58-2e0fb0f700e8",
      "metadata": {
        "id": "155efa59-4012-45de-ac58-2e0fb0f700e8"
      },
      "outputs": [],
      "source": [
        "kmeans = KMeans(n_clusters=2, random_state=42)\n",
        "kmeans.fit(X_train)\n",
        "y_pred_kmeans = kmeans.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87bf7ca8-213c-439d-87ac-58427e2c8f1b",
      "metadata": {
        "id": "87bf7ca8-213c-439d-87ac-58427e2c8f1b"
      },
      "outputs": [],
      "source": [
        "y_pred_kmeans = np.where(y_pred_kmeans == 0, 1, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07548ad2-083e-428a-9936-ca43577584a9",
      "metadata": {
        "id": "07548ad2-083e-428a-9936-ca43577584a9",
        "outputId": "b2695bfc-0eaf-45da-be9b-24e08adade7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---KMeans Clustering (adjusted for survival)---\n",
            "Accuracy: 0.01\n",
            "Precision: 0.00\n",
            "Recall: 0.01\n",
            "F1 Score: 0.00\n",
            "Confusion Matrix:\n",
            "[[1 0 0 ... 0 0 0]\n",
            " [0 2 0 ... 0 0 0]\n",
            " [2 2 0 ... 0 0 0]\n",
            " ...\n",
            " [4 0 0 ... 0 0 0]\n",
            " [1 0 0 ... 0 0 0]\n",
            " [3 0 0 ... 0 0 0]]\n",
            "----------------------------------------\n"
          ]
        }
      ],
      "source": [
        "evaluate_model(y_test, y_pred_kmeans, \"KMeans Clustering (adjusted for survival)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "284ce7dd-5188-4786-92b6-569eda6c93fe",
      "metadata": {
        "id": "284ce7dd-5188-4786-92b6-569eda6c93fe",
        "outputId": "2b3d71b7-45a1-4929-e367-12db166c3dba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Classification Reports ---\n",
            "Logistic Regression:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67         1\n",
            "           1       0.40      1.00      0.57         2\n",
            "           2       1.00      1.00      1.00         4\n",
            "           3       1.00      0.67      0.80         3\n",
            "           4       0.33      0.33      0.33         3\n",
            "           5       0.67      0.67      0.67         3\n",
            "           6       1.00      0.40      0.57         5\n",
            "           7       1.00      1.00      1.00         2\n",
            "           8       1.00      1.00      1.00         4\n",
            "           9       0.50      1.00      0.67         2\n",
            "          10       1.00      0.60      0.75         5\n",
            "          11       1.00      1.00      1.00         5\n",
            "          12       0.80      1.00      0.89         4\n",
            "          13       0.83      1.00      0.91         5\n",
            "          14       1.00      0.50      0.67         4\n",
            "          15       1.00      0.33      0.50         3\n",
            "          16       0.50      0.25      0.33         4\n",
            "          17       0.67      0.67      0.67         3\n",
            "          18       1.00      1.00      1.00         4\n",
            "          19       1.00      0.75      0.86         4\n",
            "          20       1.00      1.00      1.00         5\n",
            "          21       0.00      0.00      0.00         0\n",
            "          22       0.83      1.00      0.91         5\n",
            "          23       0.00      0.00      0.00         1\n",
            "          24       1.00      0.50      0.67         2\n",
            "          25       0.80      0.57      0.67         7\n",
            "          26       0.50      1.00      0.67         4\n",
            "          27       1.00      0.75      0.86         4\n",
            "          28       1.00      0.50      0.67         4\n",
            "          29       1.00      0.67      0.80         3\n",
            "          30       0.60      0.60      0.60         5\n",
            "          31       0.60      1.00      0.75         3\n",
            "          32       0.50      0.40      0.44         5\n",
            "          33       0.75      0.75      0.75         4\n",
            "          34       1.00      1.00      1.00         6\n",
            "          35       0.00      0.00      0.00         1\n",
            "          36       0.80      0.80      0.80         5\n",
            "          37       0.50      0.50      0.50         2\n",
            "          39       0.00      0.00      0.00         0\n",
            "          40       0.67      1.00      0.80         4\n",
            "          41       0.50      1.00      0.67         1\n",
            "          42       0.80      1.00      0.89         4\n",
            "          43       0.80      1.00      0.89         4\n",
            "          44       1.00      0.80      0.89         5\n",
            "          45       0.50      1.00      0.67         2\n",
            "          46       1.00      1.00      1.00         2\n",
            "          47       0.17      0.50      0.25         2\n",
            "          48       1.00      1.00      1.00         4\n",
            "          50       1.00      1.00      1.00         2\n",
            "          51       0.00      0.00      0.00         1\n",
            "          52       0.67      0.80      0.73         5\n",
            "          53       0.00      0.00      0.00         2\n",
            "          54       1.00      0.33      0.50         3\n",
            "          55       1.00      1.00      1.00         3\n",
            "          56       0.25      0.20      0.22         5\n",
            "          57       1.00      1.00      1.00         2\n",
            "          58       1.00      1.00      1.00         4\n",
            "          59       0.14      1.00      0.25         1\n",
            "          60       0.80      0.80      0.80         5\n",
            "          61       1.00      1.00      1.00         2\n",
            "          62       1.00      1.00      1.00         1\n",
            "          63       1.00      0.50      0.67         2\n",
            "          64       0.00      0.00      0.00         3\n",
            "          65       0.50      0.40      0.44         5\n",
            "          66       0.75      0.50      0.60         6\n",
            "          67       1.00      1.00      1.00         4\n",
            "          68       1.00      0.75      0.86         4\n",
            "          69       1.00      0.20      0.33         5\n",
            "          70       1.00      1.00      1.00         5\n",
            "          71       0.67      0.50      0.57         4\n",
            "          72       0.57      1.00      0.73         4\n",
            "          73       0.33      1.00      0.50         2\n",
            "          74       0.00      0.00      0.00         0\n",
            "          75       0.00      0.00      0.00         1\n",
            "          76       1.00      1.00      1.00         4\n",
            "          77       1.00      0.83      0.91         6\n",
            "          78       1.00      1.00      1.00         7\n",
            "          79       1.00      0.67      0.80         3\n",
            "          80       1.00      1.00      1.00         2\n",
            "          81       0.33      1.00      0.50         1\n",
            "          82       1.00      0.60      0.75         5\n",
            "          83       1.00      1.00      1.00         1\n",
            "          84       0.80      1.00      0.89         4\n",
            "          85       1.00      0.67      0.80         6\n",
            "          86       1.00      1.00      1.00         1\n",
            "          87       1.00      0.71      0.83         7\n",
            "          88       1.00      1.00      1.00         1\n",
            "          89       0.50      0.50      0.50         2\n",
            "          90       1.00      0.50      0.67         4\n",
            "          91       0.57      0.67      0.62         6\n",
            "          92       1.00      0.25      0.40         4\n",
            "          93       0.50      1.00      0.67         2\n",
            "          94       0.00      0.00      0.00         1\n",
            "          95       0.60      0.60      0.60         5\n",
            "          96       0.50      0.67      0.57         3\n",
            "          97       0.60      1.00      0.75         3\n",
            "          98       1.00      1.00      1.00         4\n",
            "          99       0.60      0.75      0.67         4\n",
            "         100       0.00      0.00      0.00         1\n",
            "         101       1.00      1.00      1.00         2\n",
            "         102       1.00      1.00      1.00         7\n",
            "         103       0.00      0.00      0.00         1\n",
            "         104       0.33      1.00      0.50         1\n",
            "         106       0.33      0.50      0.40         2\n",
            "         107       1.00      1.00      1.00         2\n",
            "         108       1.00      1.00      1.00         2\n",
            "         109       0.75      1.00      0.86         3\n",
            "         111       0.50      1.00      0.67         2\n",
            "         112       1.00      0.25      0.40         4\n",
            "         113       0.50      1.00      0.67         1\n",
            "         114       0.83      0.83      0.83         6\n",
            "         115       0.60      1.00      0.75         3\n",
            "         116       1.00      1.00      1.00         4\n",
            "         118       1.00      1.00      1.00         2\n",
            "         119       1.00      0.60      0.75         5\n",
            "         120       1.00      0.67      0.80         3\n",
            "         121       1.00      0.25      0.40         4\n",
            "         122       0.25      0.33      0.29         3\n",
            "         123       1.00      1.00      1.00         3\n",
            "         125       1.00      1.00      1.00         5\n",
            "         126       1.00      1.00      1.00         2\n",
            "         127       1.00      0.75      0.86         4\n",
            "         129       0.50      1.00      0.67         1\n",
            "         130       0.67      1.00      0.80         2\n",
            "         131       0.33      0.50      0.40         2\n",
            "         132       0.33      0.50      0.40         2\n",
            "         133       0.75      1.00      0.86         3\n",
            "         134       1.00      0.50      0.67         2\n",
            "         135       0.67      0.67      0.67         3\n",
            "         136       1.00      1.00      1.00         4\n",
            "         137       0.71      0.83      0.77         6\n",
            "         138       0.67      0.50      0.57         4\n",
            "         139       0.40      0.50      0.44         4\n",
            "         140       1.00      1.00      1.00         1\n",
            "         141       0.00      0.00      0.00         1\n",
            "         143       0.33      0.50      0.40         2\n",
            "         144       1.00      0.75      0.86         4\n",
            "         145       0.75      0.75      0.75         4\n",
            "         146       0.00      0.00      0.00         1\n",
            "         147       0.50      0.33      0.40         3\n",
            "         148       1.00      1.00      1.00         2\n",
            "         149       1.00      0.33      0.50         3\n",
            "         150       1.00      0.33      0.50         3\n",
            "         151       0.00      0.00      0.00         0\n",
            "         152       0.33      0.50      0.40         2\n",
            "         153       1.00      1.00      1.00         1\n",
            "         154       1.00      0.75      0.86         4\n",
            "         155       1.00      1.00      1.00         5\n",
            "         156       0.57      0.80      0.67         5\n",
            "         157       1.00      1.00      1.00         4\n",
            "         158       1.00      1.00      1.00         4\n",
            "         159       1.00      1.00      1.00         3\n",
            "         160       0.50      1.00      0.67         2\n",
            "         161       1.00      1.00      1.00         2\n",
            "         162       1.00      0.67      0.80         3\n",
            "         163       1.00      0.80      0.89         5\n",
            "         164       0.67      1.00      0.80         2\n",
            "         165       1.00      1.00      1.00         2\n",
            "         166       1.00      0.80      0.89         5\n",
            "         167       1.00      1.00      1.00         3\n",
            "         168       1.00      0.50      0.67         2\n",
            "         169       1.00      0.67      0.80         6\n",
            "         170       0.80      0.80      0.80         5\n",
            "         171       0.80      0.80      0.80         5\n",
            "         172       1.00      1.00      1.00         4\n",
            "         173       0.75      0.75      0.75         4\n",
            "         174       1.00      1.00      1.00         3\n",
            "         175       0.75      1.00      0.86         3\n",
            "         176       1.00      0.50      0.67         2\n",
            "         177       0.75      0.75      0.75         4\n",
            "         178       0.00      0.00      0.00         1\n",
            "         179       1.00      0.83      0.91         6\n",
            "         181       0.75      1.00      0.86         3\n",
            "         182       1.00      1.00      1.00         1\n",
            "         183       1.00      0.67      0.80         3\n",
            "         184       1.00      1.00      1.00         3\n",
            "         185       1.00      1.00      1.00         2\n",
            "         186       0.60      1.00      0.75         3\n",
            "         187       1.00      1.00      1.00         2\n",
            "         188       1.00      0.75      0.86         4\n",
            "         189       1.00      1.00      1.00         2\n",
            "         190       1.00      1.00      1.00         4\n",
            "         191       0.50      1.00      0.67         1\n",
            "         192       1.00      0.33      0.50         3\n",
            "\n",
            "    accuracy                           0.76       588\n",
            "   macro avg       0.74      0.73      0.70       588\n",
            "weighted avg       0.82      0.76      0.76       588\n",
            "\n",
            "Naive Bayes:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         1\n",
            "           1       1.00      1.00      1.00         2\n",
            "           2       1.00      1.00      1.00         4\n",
            "           3       1.00      1.00      1.00         3\n",
            "           4       1.00      1.00      1.00         3\n",
            "           5       0.60      1.00      0.75         3\n",
            "           6       1.00      0.60      0.75         5\n",
            "           7       1.00      1.00      1.00         2\n",
            "           8       1.00      1.00      1.00         4\n",
            "           9       1.00      1.00      1.00         2\n",
            "          10       1.00      1.00      1.00         5\n",
            "          11       1.00      1.00      1.00         5\n",
            "          12       1.00      1.00      1.00         4\n",
            "          13       1.00      1.00      1.00         5\n",
            "          14       1.00      1.00      1.00         4\n",
            "          15       1.00      1.00      1.00         3\n",
            "          16       1.00      1.00      1.00         4\n",
            "          17       1.00      1.00      1.00         3\n",
            "          18       1.00      1.00      1.00         4\n",
            "          19       1.00      1.00      1.00         4\n",
            "          20       1.00      1.00      1.00         5\n",
            "          22       1.00      1.00      1.00         5\n",
            "          23       1.00      1.00      1.00         1\n",
            "          24       1.00      1.00      1.00         2\n",
            "          25       1.00      1.00      1.00         7\n",
            "          26       1.00      1.00      1.00         4\n",
            "          27       1.00      1.00      1.00         4\n",
            "          28       1.00      1.00      1.00         4\n",
            "          29       1.00      1.00      1.00         3\n",
            "          30       1.00      1.00      1.00         5\n",
            "          31       1.00      1.00      1.00         3\n",
            "          32       1.00      1.00      1.00         5\n",
            "          33       1.00      1.00      1.00         4\n",
            "          34       1.00      1.00      1.00         6\n",
            "          35       1.00      1.00      1.00         1\n",
            "          36       1.00      1.00      1.00         5\n",
            "          37       1.00      1.00      1.00         2\n",
            "          40       1.00      1.00      1.00         4\n",
            "          41       1.00      1.00      1.00         1\n",
            "          42       1.00      1.00      1.00         4\n",
            "          43       1.00      1.00      1.00         4\n",
            "          44       1.00      1.00      1.00         5\n",
            "          45       1.00      1.00      1.00         2\n",
            "          46       1.00      1.00      1.00         2\n",
            "          47       1.00      1.00      1.00         2\n",
            "          48       1.00      1.00      1.00         4\n",
            "          50       1.00      1.00      1.00         2\n",
            "          51       1.00      1.00      1.00         1\n",
            "          52       1.00      1.00      1.00         5\n",
            "          53       1.00      1.00      1.00         2\n",
            "          54       1.00      1.00      1.00         3\n",
            "          55       1.00      1.00      1.00         3\n",
            "          56       1.00      1.00      1.00         5\n",
            "          57       1.00      1.00      1.00         2\n",
            "          58       0.80      1.00      0.89         4\n",
            "          59       0.00      0.00      0.00         1\n",
            "          60       1.00      1.00      1.00         5\n",
            "          61       1.00      1.00      1.00         2\n",
            "          62       1.00      1.00      1.00         1\n",
            "          63       1.00      1.00      1.00         2\n",
            "          64       1.00      1.00      1.00         3\n",
            "          65       1.00      1.00      1.00         5\n",
            "          66       1.00      1.00      1.00         6\n",
            "          67       1.00      1.00      1.00         4\n",
            "          68       1.00      1.00      1.00         4\n",
            "          69       1.00      1.00      1.00         5\n",
            "          70       1.00      1.00      1.00         5\n",
            "          71       1.00      1.00      1.00         4\n",
            "          72       1.00      1.00      1.00         4\n",
            "          73       1.00      1.00      1.00         2\n",
            "          75       1.00      1.00      1.00         1\n",
            "          76       1.00      1.00      1.00         4\n",
            "          77       1.00      1.00      1.00         6\n",
            "          78       1.00      1.00      1.00         7\n",
            "          79       1.00      1.00      1.00         3\n",
            "          80       1.00      1.00      1.00         2\n",
            "          81       1.00      1.00      1.00         1\n",
            "          82       1.00      1.00      1.00         5\n",
            "          83       1.00      1.00      1.00         1\n",
            "          84       1.00      1.00      1.00         4\n",
            "          85       1.00      1.00      1.00         6\n",
            "          86       1.00      1.00      1.00         1\n",
            "          87       1.00      1.00      1.00         7\n",
            "          88       1.00      1.00      1.00         1\n",
            "          89       1.00      1.00      1.00         2\n",
            "          90       1.00      1.00      1.00         4\n",
            "          91       1.00      1.00      1.00         6\n",
            "          92       1.00      1.00      1.00         4\n",
            "          93       1.00      1.00      1.00         2\n",
            "          94       1.00      1.00      1.00         1\n",
            "          95       0.83      1.00      0.91         5\n",
            "          96       1.00      0.67      0.80         3\n",
            "          97       0.75      1.00      0.86         3\n",
            "          98       1.00      0.75      0.86         4\n",
            "          99       1.00      1.00      1.00         4\n",
            "         100       1.00      1.00      1.00         1\n",
            "         101       1.00      1.00      1.00         2\n",
            "         102       1.00      1.00      1.00         7\n",
            "         103       1.00      1.00      1.00         1\n",
            "         104       1.00      1.00      1.00         1\n",
            "         106       1.00      1.00      1.00         2\n",
            "         107       1.00      1.00      1.00         2\n",
            "         108       1.00      1.00      1.00         2\n",
            "         109       1.00      1.00      1.00         3\n",
            "         111       1.00      1.00      1.00         2\n",
            "         112       1.00      1.00      1.00         4\n",
            "         113       1.00      1.00      1.00         1\n",
            "         114       1.00      1.00      1.00         6\n",
            "         115       1.00      1.00      1.00         3\n",
            "         116       1.00      1.00      1.00         4\n",
            "         118       1.00      1.00      1.00         2\n",
            "         119       1.00      1.00      1.00         5\n",
            "         120       1.00      1.00      1.00         3\n",
            "         121       1.00      1.00      1.00         4\n",
            "         122       1.00      1.00      1.00         3\n",
            "         123       1.00      1.00      1.00         3\n",
            "         125       1.00      1.00      1.00         5\n",
            "         126       1.00      1.00      1.00         2\n",
            "         127       1.00      1.00      1.00         4\n",
            "         129       1.00      1.00      1.00         1\n",
            "         130       1.00      1.00      1.00         2\n",
            "         131       1.00      1.00      1.00         2\n",
            "         132       1.00      1.00      1.00         2\n",
            "         133       1.00      1.00      1.00         3\n",
            "         134       1.00      1.00      1.00         2\n",
            "         135       1.00      1.00      1.00         3\n",
            "         136       1.00      1.00      1.00         4\n",
            "         137       1.00      1.00      1.00         6\n",
            "         138       1.00      1.00      1.00         4\n",
            "         139       1.00      1.00      1.00         4\n",
            "         140       1.00      1.00      1.00         1\n",
            "         141       1.00      1.00      1.00         1\n",
            "         143       1.00      1.00      1.00         2\n",
            "         144       1.00      1.00      1.00         4\n",
            "         145       1.00      1.00      1.00         4\n",
            "         146       0.00      0.00      0.00         1\n",
            "         147       0.75      1.00      0.86         3\n",
            "         148       1.00      1.00      1.00         2\n",
            "         149       1.00      1.00      1.00         3\n",
            "         150       1.00      1.00      1.00         3\n",
            "         152       1.00      1.00      1.00         2\n",
            "         153       1.00      1.00      1.00         1\n",
            "         154       1.00      1.00      1.00         4\n",
            "         155       1.00      1.00      1.00         5\n",
            "         156       1.00      1.00      1.00         5\n",
            "         157       1.00      1.00      1.00         4\n",
            "         158       1.00      1.00      1.00         4\n",
            "         159       1.00      1.00      1.00         3\n",
            "         160       1.00      1.00      1.00         2\n",
            "         161       1.00      1.00      1.00         2\n",
            "         162       1.00      1.00      1.00         3\n",
            "         163       1.00      1.00      1.00         5\n",
            "         164       1.00      1.00      1.00         2\n",
            "         165       1.00      1.00      1.00         2\n",
            "         166       1.00      1.00      1.00         5\n",
            "         167       1.00      1.00      1.00         3\n",
            "         168       1.00      1.00      1.00         2\n",
            "         169       1.00      1.00      1.00         6\n",
            "         170       1.00      1.00      1.00         5\n",
            "         171       1.00      1.00      1.00         5\n",
            "         172       1.00      1.00      1.00         4\n",
            "         173       1.00      1.00      1.00         4\n",
            "         174       1.00      1.00      1.00         3\n",
            "         175       1.00      1.00      1.00         3\n",
            "         176       1.00      1.00      1.00         2\n",
            "         177       1.00      1.00      1.00         4\n",
            "         178       0.00      0.00      0.00         1\n",
            "         179       0.86      1.00      0.92         6\n",
            "         181       1.00      1.00      1.00         3\n",
            "         182       1.00      1.00      1.00         1\n",
            "         183       1.00      1.00      1.00         3\n",
            "         184       1.00      1.00      1.00         3\n",
            "         185       1.00      1.00      1.00         2\n",
            "         186       1.00      1.00      1.00         3\n",
            "         187       1.00      1.00      1.00         2\n",
            "         188       1.00      1.00      1.00         4\n",
            "         189       1.00      1.00      1.00         2\n",
            "         190       1.00      1.00      1.00         4\n",
            "         191       1.00      1.00      1.00         1\n",
            "         192       1.00      1.00      1.00         3\n",
            "\n",
            "    accuracy                           0.99       588\n",
            "   macro avg       0.98      0.98      0.98       588\n",
            "weighted avg       0.99      0.99      0.99       588\n",
            "\n",
            "K-Nearest Neighbors:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         1\n",
            "           1       0.33      1.00      0.50         2\n",
            "           2       0.57      1.00      0.73         4\n",
            "           3       1.00      0.67      0.80         3\n",
            "           4       0.67      0.67      0.67         3\n",
            "           5       1.00      0.67      0.80         3\n",
            "           6       1.00      0.40      0.57         5\n",
            "           7       0.50      0.50      0.50         2\n",
            "           8       0.57      1.00      0.73         4\n",
            "           9       0.50      0.50      0.50         2\n",
            "          10       0.40      0.40      0.40         5\n",
            "          11       1.00      0.60      0.75         5\n",
            "          12       0.60      0.75      0.67         4\n",
            "          13       0.83      1.00      0.91         5\n",
            "          14       1.00      0.50      0.67         4\n",
            "          15       0.22      0.67      0.33         3\n",
            "          16       0.50      0.25      0.33         4\n",
            "          17       0.33      0.67      0.44         3\n",
            "          18       1.00      1.00      1.00         4\n",
            "          19       1.00      0.75      0.86         4\n",
            "          20       0.25      0.20      0.22         5\n",
            "          22       0.80      0.80      0.80         5\n",
            "          23       0.00      0.00      0.00         1\n",
            "          24       0.25      0.50      0.33         2\n",
            "          25       0.25      0.14      0.18         7\n",
            "          26       0.43      0.75      0.55         4\n",
            "          27       1.00      0.75      0.86         4\n",
            "          28       1.00      0.25      0.40         4\n",
            "          29       0.20      0.33      0.25         3\n",
            "          30       0.50      0.20      0.29         5\n",
            "          31       0.50      0.67      0.57         3\n",
            "          32       0.29      0.40      0.33         5\n",
            "          33       1.00      0.75      0.86         4\n",
            "          34       1.00      1.00      1.00         6\n",
            "          35       0.00      0.00      0.00         1\n",
            "          36       0.40      0.40      0.40         5\n",
            "          37       0.25      0.50      0.33         2\n",
            "          39       0.00      0.00      0.00         0\n",
            "          40       0.43      0.75      0.55         4\n",
            "          41       1.00      1.00      1.00         1\n",
            "          42       0.33      0.25      0.29         4\n",
            "          43       1.00      0.75      0.86         4\n",
            "          44       0.57      0.80      0.67         5\n",
            "          45       0.29      1.00      0.44         2\n",
            "          46       1.00      0.50      0.67         2\n",
            "          47       0.00      0.00      0.00         2\n",
            "          48       1.00      1.00      1.00         4\n",
            "          49       0.00      0.00      0.00         0\n",
            "          50       0.33      0.50      0.40         2\n",
            "          51       0.00      0.00      0.00         1\n",
            "          52       0.60      0.60      0.60         5\n",
            "          53       0.00      0.00      0.00         2\n",
            "          54       1.00      0.33      0.50         3\n",
            "          55       0.67      0.67      0.67         3\n",
            "          56       1.00      0.80      0.89         5\n",
            "          57       0.33      1.00      0.50         2\n",
            "          58       0.75      0.75      0.75         4\n",
            "          59       0.00      0.00      0.00         1\n",
            "          60       0.60      0.60      0.60         5\n",
            "          61       1.00      1.00      1.00         2\n",
            "          62       0.25      1.00      0.40         1\n",
            "          63       1.00      1.00      1.00         2\n",
            "          64       0.50      0.33      0.40         3\n",
            "          65       0.60      0.60      0.60         5\n",
            "          66       1.00      0.33      0.50         6\n",
            "          67       0.80      1.00      0.89         4\n",
            "          68       0.50      0.75      0.60         4\n",
            "          69       0.67      0.40      0.50         5\n",
            "          70       0.50      0.80      0.62         5\n",
            "          71       0.67      0.50      0.57         4\n",
            "          72       0.67      1.00      0.80         4\n",
            "          73       0.25      0.50      0.33         2\n",
            "          75       0.25      1.00      0.40         1\n",
            "          76       1.00      1.00      1.00         4\n",
            "          77       1.00      0.33      0.50         6\n",
            "          78       1.00      1.00      1.00         7\n",
            "          79       0.50      0.67      0.57         3\n",
            "          80       0.00      0.00      0.00         2\n",
            "          81       0.50      1.00      0.67         1\n",
            "          82       0.33      0.20      0.25         5\n",
            "          83       0.17      1.00      0.29         1\n",
            "          84       0.60      0.75      0.67         4\n",
            "          85       1.00      0.67      0.80         6\n",
            "          86       1.00      1.00      1.00         1\n",
            "          87       1.00      0.57      0.73         7\n",
            "          88       0.00      0.00      0.00         1\n",
            "          89       0.50      1.00      0.67         2\n",
            "          90       0.75      0.75      0.75         4\n",
            "          91       0.50      0.50      0.50         6\n",
            "          92       1.00      0.50      0.67         4\n",
            "          93       0.50      1.00      0.67         2\n",
            "          94       0.00      0.00      0.00         1\n",
            "          95       0.67      0.40      0.50         5\n",
            "          96       0.67      0.67      0.67         3\n",
            "          97       0.67      0.67      0.67         3\n",
            "          98       0.75      0.75      0.75         4\n",
            "          99       0.50      0.75      0.60         4\n",
            "         100       0.00      0.00      0.00         1\n",
            "         101       1.00      0.50      0.67         2\n",
            "         102       1.00      1.00      1.00         7\n",
            "         103       0.00      0.00      0.00         1\n",
            "         104       0.00      0.00      0.00         1\n",
            "         106       0.33      0.50      0.40         2\n",
            "         107       0.67      1.00      0.80         2\n",
            "         108       0.00      0.00      0.00         2\n",
            "         109       1.00      0.67      0.80         3\n",
            "         111       0.50      0.50      0.50         2\n",
            "         112       0.67      0.50      0.57         4\n",
            "         113       1.00      1.00      1.00         1\n",
            "         114       0.60      0.50      0.55         6\n",
            "         115       0.50      0.67      0.57         3\n",
            "         116       0.60      0.75      0.67         4\n",
            "         118       1.00      1.00      1.00         2\n",
            "         119       0.33      0.20      0.25         5\n",
            "         120       0.00      0.00      0.00         3\n",
            "         121       0.50      0.25      0.33         4\n",
            "         122       0.50      0.33      0.40         3\n",
            "         123       1.00      1.00      1.00         3\n",
            "         125       0.67      0.40      0.50         5\n",
            "         126       1.00      1.00      1.00         2\n",
            "         127       1.00      0.75      0.86         4\n",
            "         129       0.50      1.00      0.67         1\n",
            "         130       1.00      1.00      1.00         2\n",
            "         131       0.00      0.00      0.00         2\n",
            "         132       1.00      0.50      0.67         2\n",
            "         133       0.50      0.33      0.40         3\n",
            "         134       1.00      1.00      1.00         2\n",
            "         135       0.33      0.33      0.33         3\n",
            "         136       1.00      0.50      0.67         4\n",
            "         137       1.00      0.83      0.91         6\n",
            "         138       1.00      0.75      0.86         4\n",
            "         139       0.75      0.75      0.75         4\n",
            "         140       1.00      1.00      1.00         1\n",
            "         141       0.00      0.00      0.00         1\n",
            "         143       0.33      0.50      0.40         2\n",
            "         144       1.00      0.25      0.40         4\n",
            "         145       0.67      1.00      0.80         4\n",
            "         146       0.00      0.00      0.00         1\n",
            "         147       0.50      0.67      0.57         3\n",
            "         148       1.00      1.00      1.00         2\n",
            "         149       1.00      0.67      0.80         3\n",
            "         150       0.75      1.00      0.86         3\n",
            "         151       0.00      0.00      0.00         0\n",
            "         152       0.50      0.50      0.50         2\n",
            "         153       1.00      1.00      1.00         1\n",
            "         154       0.75      0.75      0.75         4\n",
            "         155       0.75      0.60      0.67         5\n",
            "         156       0.67      0.40      0.50         5\n",
            "         157       0.80      1.00      0.89         4\n",
            "         158       1.00      0.50      0.67         4\n",
            "         159       1.00      1.00      1.00         3\n",
            "         160       1.00      0.50      0.67         2\n",
            "         161       1.00      1.00      1.00         2\n",
            "         162       1.00      0.67      0.80         3\n",
            "         163       1.00      0.40      0.57         5\n",
            "         164       0.00      0.00      0.00         2\n",
            "         165       1.00      0.50      0.67         2\n",
            "         166       1.00      0.60      0.75         5\n",
            "         167       1.00      0.67      0.80         3\n",
            "         168       1.00      1.00      1.00         2\n",
            "         169       1.00      1.00      1.00         6\n",
            "         170       0.67      0.80      0.73         5\n",
            "         171       1.00      0.60      0.75         5\n",
            "         172       0.75      0.75      0.75         4\n",
            "         173       0.00      0.00      0.00         4\n",
            "         174       1.00      0.33      0.50         3\n",
            "         175       1.00      0.67      0.80         3\n",
            "         176       0.50      0.50      0.50         2\n",
            "         177       0.75      0.75      0.75         4\n",
            "         178       0.00      0.00      0.00         1\n",
            "         179       0.67      0.33      0.44         6\n",
            "         180       0.00      0.00      0.00         0\n",
            "         181       0.60      1.00      0.75         3\n",
            "         182       1.00      1.00      1.00         1\n",
            "         183       0.00      0.00      0.00         3\n",
            "         184       1.00      1.00      1.00         3\n",
            "         185       1.00      1.00      1.00         2\n",
            "         186       0.60      1.00      0.75         3\n",
            "         187       1.00      1.00      1.00         2\n",
            "         188       1.00      0.25      0.40         4\n",
            "         189       1.00      1.00      1.00         2\n",
            "         190       1.00      1.00      1.00         4\n",
            "         191       0.33      1.00      0.50         1\n",
            "         192       0.00      0.00      0.00         3\n",
            "\n",
            "    accuracy                           0.62       588\n",
            "   macro avg       0.62      0.60      0.58       588\n",
            "weighted avg       0.69      0.62      0.62       588\n",
            "\n",
            "Decision Tree:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         1\n",
            "           1       1.00      1.00      1.00         2\n",
            "           2       1.00      1.00      1.00         4\n",
            "           3       1.00      1.00      1.00         3\n",
            "           4       1.00      1.00      1.00         3\n",
            "           5       1.00      1.00      1.00         3\n",
            "           6       1.00      1.00      1.00         5\n",
            "           7       1.00      1.00      1.00         2\n",
            "           8       1.00      1.00      1.00         4\n",
            "           9       1.00      1.00      1.00         2\n",
            "          10       1.00      0.80      0.89         5\n",
            "          11       1.00      1.00      1.00         5\n",
            "          12       1.00      1.00      1.00         4\n",
            "          13       0.83      1.00      0.91         5\n",
            "          14       0.75      0.75      0.75         4\n",
            "          15       1.00      1.00      1.00         3\n",
            "          16       1.00      1.00      1.00         4\n",
            "          17       1.00      1.00      1.00         3\n",
            "          18       1.00      1.00      1.00         4\n",
            "          19       1.00      1.00      1.00         4\n",
            "          20       1.00      1.00      1.00         5\n",
            "          22       1.00      1.00      1.00         5\n",
            "          23       1.00      1.00      1.00         1\n",
            "          24       1.00      1.00      1.00         2\n",
            "          25       0.88      1.00      0.93         7\n",
            "          26       0.67      1.00      0.80         4\n",
            "          27       1.00      1.00      1.00         4\n",
            "          28       1.00      0.50      0.67         4\n",
            "          29       1.00      0.67      0.80         3\n",
            "          30       1.00      1.00      1.00         5\n",
            "          31       1.00      1.00      1.00         3\n",
            "          32       1.00      1.00      1.00         5\n",
            "          33       1.00      1.00      1.00         4\n",
            "          34       1.00      1.00      1.00         6\n",
            "          35       1.00      1.00      1.00         1\n",
            "          36       1.00      1.00      1.00         5\n",
            "          37       1.00      1.00      1.00         2\n",
            "          40       1.00      1.00      1.00         4\n",
            "          41       1.00      1.00      1.00         1\n",
            "          42       1.00      1.00      1.00         4\n",
            "          43       1.00      1.00      1.00         4\n",
            "          44       1.00      1.00      1.00         5\n",
            "          45       1.00      1.00      1.00         2\n",
            "          46       1.00      1.00      1.00         2\n",
            "          47       1.00      1.00      1.00         2\n",
            "          48       1.00      1.00      1.00         4\n",
            "          50       1.00      1.00      1.00         2\n",
            "          51       1.00      1.00      1.00         1\n",
            "          52       1.00      1.00      1.00         5\n",
            "          53       1.00      1.00      1.00         2\n",
            "          54       1.00      1.00      1.00         3\n",
            "          55       1.00      1.00      1.00         3\n",
            "          56       1.00      1.00      1.00         5\n",
            "          57       1.00      1.00      1.00         2\n",
            "          58       1.00      1.00      1.00         4\n",
            "          59       1.00      1.00      1.00         1\n",
            "          60       1.00      1.00      1.00         5\n",
            "          61       1.00      1.00      1.00         2\n",
            "          62       1.00      1.00      1.00         1\n",
            "          63       1.00      1.00      1.00         2\n",
            "          64       1.00      1.00      1.00         3\n",
            "          65       0.71      1.00      0.83         5\n",
            "          66       1.00      1.00      1.00         6\n",
            "          67       1.00      1.00      1.00         4\n",
            "          68       1.00      1.00      1.00         4\n",
            "          69       1.00      0.60      0.75         5\n",
            "          70       1.00      1.00      1.00         5\n",
            "          71       1.00      1.00      1.00         4\n",
            "          72       1.00      1.00      1.00         4\n",
            "          73       1.00      1.00      1.00         2\n",
            "          75       1.00      1.00      1.00         1\n",
            "          76       1.00      1.00      1.00         4\n",
            "          77       1.00      1.00      1.00         6\n",
            "          78       1.00      1.00      1.00         7\n",
            "          79       1.00      1.00      1.00         3\n",
            "          80       1.00      1.00      1.00         2\n",
            "          81       1.00      1.00      1.00         1\n",
            "          82       1.00      1.00      1.00         5\n",
            "          83       1.00      1.00      1.00         1\n",
            "          84       1.00      1.00      1.00         4\n",
            "          85       1.00      1.00      1.00         6\n",
            "          86       1.00      1.00      1.00         1\n",
            "          87       1.00      1.00      1.00         7\n",
            "          88       1.00      1.00      1.00         1\n",
            "          89       1.00      1.00      1.00         2\n",
            "          90       1.00      1.00      1.00         4\n",
            "          91       1.00      1.00      1.00         6\n",
            "          92       1.00      1.00      1.00         4\n",
            "          93       1.00      1.00      1.00         2\n",
            "          94       1.00      1.00      1.00         1\n",
            "          95       1.00      1.00      1.00         5\n",
            "          96       1.00      0.67      0.80         3\n",
            "          97       0.75      1.00      0.86         3\n",
            "          98       1.00      1.00      1.00         4\n",
            "          99       1.00      1.00      1.00         4\n",
            "         100       1.00      1.00      1.00         1\n",
            "         101       1.00      1.00      1.00         2\n",
            "         102       1.00      1.00      1.00         7\n",
            "         103       1.00      1.00      1.00         1\n",
            "         104       1.00      1.00      1.00         1\n",
            "         106       1.00      1.00      1.00         2\n",
            "         107       1.00      1.00      1.00         2\n",
            "         108       1.00      1.00      1.00         2\n",
            "         109       1.00      1.00      1.00         3\n",
            "         111       1.00      1.00      1.00         2\n",
            "         112       1.00      1.00      1.00         4\n",
            "         113       1.00      1.00      1.00         1\n",
            "         114       1.00      0.67      0.80         6\n",
            "         115       1.00      1.00      1.00         3\n",
            "         116       1.00      1.00      1.00         4\n",
            "         118       1.00      1.00      1.00         2\n",
            "         119       1.00      1.00      1.00         5\n",
            "         120       1.00      1.00      1.00         3\n",
            "         121       1.00      1.00      1.00         4\n",
            "         122       0.60      1.00      0.75         3\n",
            "         123       1.00      1.00      1.00         3\n",
            "         125       1.00      1.00      1.00         5\n",
            "         126       1.00      1.00      1.00         2\n",
            "         127       1.00      1.00      1.00         4\n",
            "         129       1.00      1.00      1.00         1\n",
            "         130       1.00      1.00      1.00         2\n",
            "         131       1.00      1.00      1.00         2\n",
            "         132       1.00      1.00      1.00         2\n",
            "         133       1.00      1.00      1.00         3\n",
            "         134       1.00      1.00      1.00         2\n",
            "         135       1.00      1.00      1.00         3\n",
            "         136       0.80      1.00      0.89         4\n",
            "         137       1.00      1.00      1.00         6\n",
            "         138       1.00      1.00      1.00         4\n",
            "         139       1.00      1.00      1.00         4\n",
            "         140       1.00      1.00      1.00         1\n",
            "         141       1.00      1.00      1.00         1\n",
            "         143       0.50      0.50      0.50         2\n",
            "         144       1.00      1.00      1.00         4\n",
            "         145       1.00      1.00      1.00         4\n",
            "         146       0.00      0.00      0.00         1\n",
            "         147       1.00      1.00      1.00         3\n",
            "         148       1.00      1.00      1.00         2\n",
            "         149       1.00      1.00      1.00         3\n",
            "         150       1.00      1.00      1.00         3\n",
            "         152       1.00      1.00      1.00         2\n",
            "         153       1.00      1.00      1.00         1\n",
            "         154       1.00      1.00      1.00         4\n",
            "         155       1.00      1.00      1.00         5\n",
            "         156       1.00      1.00      1.00         5\n",
            "         157       1.00      1.00      1.00         4\n",
            "         158       1.00      1.00      1.00         4\n",
            "         159       1.00      1.00      1.00         3\n",
            "         160       1.00      1.00      1.00         2\n",
            "         161       1.00      1.00      1.00         2\n",
            "         162       1.00      1.00      1.00         3\n",
            "         163       1.00      0.80      0.89         5\n",
            "         164       1.00      1.00      1.00         2\n",
            "         165       1.00      1.00      1.00         2\n",
            "         166       1.00      1.00      1.00         5\n",
            "         167       1.00      1.00      1.00         3\n",
            "         168       1.00      1.00      1.00         2\n",
            "         169       1.00      1.00      1.00         6\n",
            "         170       1.00      1.00      1.00         5\n",
            "         171       0.83      1.00      0.91         5\n",
            "         172       1.00      1.00      1.00         4\n",
            "         173       1.00      1.00      1.00         4\n",
            "         174       0.75      1.00      0.86         3\n",
            "         175       1.00      1.00      1.00         3\n",
            "         176       1.00      1.00      1.00         2\n",
            "         177       1.00      1.00      1.00         4\n",
            "         178       0.00      0.00      0.00         1\n",
            "         179       1.00      1.00      1.00         6\n",
            "         181       1.00      1.00      1.00         3\n",
            "         182       1.00      1.00      1.00         1\n",
            "         183       1.00      1.00      1.00         3\n",
            "         184       1.00      1.00      1.00         3\n",
            "         185       1.00      1.00      1.00         2\n",
            "         186       1.00      1.00      1.00         3\n",
            "         187       1.00      1.00      1.00         2\n",
            "         188       1.00      1.00      1.00         4\n",
            "         189       1.00      1.00      1.00         2\n",
            "         190       1.00      1.00      1.00         4\n",
            "         191       1.00      1.00      1.00         1\n",
            "         192       1.00      1.00      1.00         3\n",
            "\n",
            "    accuracy                           0.98       588\n",
            "   macro avg       0.97      0.97      0.97       588\n",
            "weighted avg       0.98      0.98      0.97       588\n",
            "\n",
            "Random Forest:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         1\n",
            "           1       1.00      1.00      1.00         2\n",
            "           2       1.00      1.00      1.00         4\n",
            "           3       1.00      1.00      1.00         3\n",
            "           4       1.00      1.00      1.00         3\n",
            "           5       1.00      1.00      1.00         3\n",
            "           6       1.00      1.00      1.00         5\n",
            "           7       1.00      1.00      1.00         2\n",
            "           8       1.00      1.00      1.00         4\n",
            "           9       1.00      1.00      1.00         2\n",
            "          10       1.00      1.00      1.00         5\n",
            "          11       1.00      1.00      1.00         5\n",
            "          12       1.00      1.00      1.00         4\n",
            "          13       1.00      1.00      1.00         5\n",
            "          14       1.00      1.00      1.00         4\n",
            "          15       1.00      1.00      1.00         3\n",
            "          16       1.00      1.00      1.00         4\n",
            "          17       1.00      1.00      1.00         3\n",
            "          18       1.00      1.00      1.00         4\n",
            "          19       1.00      1.00      1.00         4\n",
            "          20       1.00      1.00      1.00         5\n",
            "          22       1.00      1.00      1.00         5\n",
            "          23       1.00      1.00      1.00         1\n",
            "          24       1.00      1.00      1.00         2\n",
            "          25       1.00      1.00      1.00         7\n",
            "          26       1.00      1.00      1.00         4\n",
            "          27       1.00      1.00      1.00         4\n",
            "          28       1.00      1.00      1.00         4\n",
            "          29       1.00      1.00      1.00         3\n",
            "          30       1.00      1.00      1.00         5\n",
            "          31       1.00      1.00      1.00         3\n",
            "          32       1.00      1.00      1.00         5\n",
            "          33       1.00      1.00      1.00         4\n",
            "          34       1.00      1.00      1.00         6\n",
            "          35       1.00      1.00      1.00         1\n",
            "          36       1.00      1.00      1.00         5\n",
            "          37       1.00      1.00      1.00         2\n",
            "          40       1.00      1.00      1.00         4\n",
            "          41       1.00      1.00      1.00         1\n",
            "          42       1.00      1.00      1.00         4\n",
            "          43       1.00      1.00      1.00         4\n",
            "          44       1.00      1.00      1.00         5\n",
            "          45       1.00      1.00      1.00         2\n",
            "          46       1.00      1.00      1.00         2\n",
            "          47       1.00      1.00      1.00         2\n",
            "          48       1.00      1.00      1.00         4\n",
            "          50       1.00      1.00      1.00         2\n",
            "          51       1.00      1.00      1.00         1\n",
            "          52       1.00      1.00      1.00         5\n",
            "          53       1.00      1.00      1.00         2\n",
            "          54       1.00      1.00      1.00         3\n",
            "          55       1.00      1.00      1.00         3\n",
            "          56       1.00      1.00      1.00         5\n",
            "          57       1.00      1.00      1.00         2\n",
            "          58       1.00      1.00      1.00         4\n",
            "          59       1.00      1.00      1.00         1\n",
            "          60       1.00      0.80      0.89         5\n",
            "          61       1.00      1.00      1.00         2\n",
            "          62       1.00      1.00      1.00         1\n",
            "          63       1.00      1.00      1.00         2\n",
            "          64       1.00      1.00      1.00         3\n",
            "          65       1.00      1.00      1.00         5\n",
            "          66       1.00      1.00      1.00         6\n",
            "          67       1.00      1.00      1.00         4\n",
            "          68       1.00      1.00      1.00         4\n",
            "          69       1.00      1.00      1.00         5\n",
            "          70       1.00      1.00      1.00         5\n",
            "          71       1.00      1.00      1.00         4\n",
            "          72       1.00      1.00      1.00         4\n",
            "          73       1.00      1.00      1.00         2\n",
            "          75       1.00      1.00      1.00         1\n",
            "          76       1.00      1.00      1.00         4\n",
            "          77       1.00      1.00      1.00         6\n",
            "          78       1.00      1.00      1.00         7\n",
            "          79       1.00      1.00      1.00         3\n",
            "          80       1.00      1.00      1.00         2\n",
            "          81       1.00      1.00      1.00         1\n",
            "          82       0.83      1.00      0.91         5\n",
            "          83       1.00      1.00      1.00         1\n",
            "          84       1.00      1.00      1.00         4\n",
            "          85       1.00      1.00      1.00         6\n",
            "          86       1.00      1.00      1.00         1\n",
            "          87       1.00      1.00      1.00         7\n",
            "          88       1.00      1.00      1.00         1\n",
            "          89       1.00      1.00      1.00         2\n",
            "          90       1.00      1.00      1.00         4\n",
            "          91       1.00      1.00      1.00         6\n",
            "          92       1.00      1.00      1.00         4\n",
            "          93       1.00      1.00      1.00         2\n",
            "          94       1.00      1.00      1.00         1\n",
            "          95       1.00      1.00      1.00         5\n",
            "          96       1.00      1.00      1.00         3\n",
            "          97       1.00      1.00      1.00         3\n",
            "          98       1.00      1.00      1.00         4\n",
            "          99       1.00      1.00      1.00         4\n",
            "         100       1.00      1.00      1.00         1\n",
            "         101       1.00      1.00      1.00         2\n",
            "         102       1.00      1.00      1.00         7\n",
            "         103       1.00      1.00      1.00         1\n",
            "         104       1.00      1.00      1.00         1\n",
            "         106       1.00      1.00      1.00         2\n",
            "         107       1.00      1.00      1.00         2\n",
            "         108       1.00      1.00      1.00         2\n",
            "         109       1.00      1.00      1.00         3\n",
            "         111       1.00      1.00      1.00         2\n",
            "         112       1.00      1.00      1.00         4\n",
            "         113       1.00      1.00      1.00         1\n",
            "         114       1.00      1.00      1.00         6\n",
            "         115       1.00      1.00      1.00         3\n",
            "         116       1.00      1.00      1.00         4\n",
            "         118       1.00      1.00      1.00         2\n",
            "         119       1.00      1.00      1.00         5\n",
            "         120       1.00      1.00      1.00         3\n",
            "         121       1.00      1.00      1.00         4\n",
            "         122       1.00      1.00      1.00         3\n",
            "         123       1.00      1.00      1.00         3\n",
            "         125       1.00      1.00      1.00         5\n",
            "         126       1.00      1.00      1.00         2\n",
            "         127       1.00      1.00      1.00         4\n",
            "         129       1.00      1.00      1.00         1\n",
            "         130       1.00      1.00      1.00         2\n",
            "         131       1.00      1.00      1.00         2\n",
            "         132       1.00      1.00      1.00         2\n",
            "         133       1.00      1.00      1.00         3\n",
            "         134       1.00      1.00      1.00         2\n",
            "         135       1.00      1.00      1.00         3\n",
            "         136       1.00      1.00      1.00         4\n",
            "         137       1.00      1.00      1.00         6\n",
            "         138       1.00      1.00      1.00         4\n",
            "         139       1.00      1.00      1.00         4\n",
            "         140       1.00      1.00      1.00         1\n",
            "         141       1.00      1.00      1.00         1\n",
            "         143       0.67      1.00      0.80         2\n",
            "         144       1.00      1.00      1.00         4\n",
            "         145       1.00      1.00      1.00         4\n",
            "         146       0.00      0.00      0.00         1\n",
            "         147       1.00      1.00      1.00         3\n",
            "         148       1.00      1.00      1.00         2\n",
            "         149       1.00      1.00      1.00         3\n",
            "         150       1.00      1.00      1.00         3\n",
            "         152       1.00      1.00      1.00         2\n",
            "         153       1.00      1.00      1.00         1\n",
            "         154       1.00      1.00      1.00         4\n",
            "         155       1.00      1.00      1.00         5\n",
            "         156       1.00      1.00      1.00         5\n",
            "         157       1.00      1.00      1.00         4\n",
            "         158       1.00      1.00      1.00         4\n",
            "         159       1.00      1.00      1.00         3\n",
            "         160       1.00      1.00      1.00         2\n",
            "         161       1.00      1.00      1.00         2\n",
            "         162       1.00      1.00      1.00         3\n",
            "         163       1.00      1.00      1.00         5\n",
            "         164       1.00      1.00      1.00         2\n",
            "         165       1.00      1.00      1.00         2\n",
            "         166       1.00      1.00      1.00         5\n",
            "         167       1.00      1.00      1.00         3\n",
            "         168       1.00      1.00      1.00         2\n",
            "         169       1.00      1.00      1.00         6\n",
            "         170       1.00      1.00      1.00         5\n",
            "         171       1.00      1.00      1.00         5\n",
            "         172       1.00      1.00      1.00         4\n",
            "         173       0.80      1.00      0.89         4\n",
            "         174       1.00      1.00      1.00         3\n",
            "         175       1.00      1.00      1.00         3\n",
            "         176       1.00      1.00      1.00         2\n",
            "         177       1.00      1.00      1.00         4\n",
            "         178       0.00      0.00      0.00         1\n",
            "         179       1.00      1.00      1.00         6\n",
            "         181       1.00      1.00      1.00         3\n",
            "         182       1.00      1.00      1.00         1\n",
            "         183       1.00      1.00      1.00         3\n",
            "         184       1.00      1.00      1.00         3\n",
            "         185       1.00      1.00      1.00         2\n",
            "         186       1.00      1.00      1.00         3\n",
            "         187       1.00      1.00      1.00         2\n",
            "         188       1.00      1.00      1.00         4\n",
            "         189       1.00      1.00      1.00         2\n",
            "         190       1.00      1.00      1.00         4\n",
            "         191       1.00      1.00      1.00         1\n",
            "         192       1.00      1.00      1.00         3\n",
            "\n",
            "    accuracy                           0.99       588\n",
            "   macro avg       0.99      0.99      0.99       588\n",
            "weighted avg       0.99      0.99      0.99       588\n",
            "\n",
            "KMeans (Clustering):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      1.00      0.01         1\n",
            "           1       0.01      1.00      0.01         2\n",
            "           2       0.00      0.00      0.00         4\n",
            "           3       0.00      0.00      0.00         3\n",
            "           4       0.00      0.00      0.00         3\n",
            "           5       0.00      0.00      0.00         3\n",
            "           6       0.00      0.00      0.00         5\n",
            "           7       0.00      0.00      0.00         2\n",
            "           8       0.00      0.00      0.00         4\n",
            "           9       0.00      0.00      0.00         2\n",
            "          10       0.00      0.00      0.00         5\n",
            "          11       0.00      0.00      0.00         5\n",
            "          12       0.00      0.00      0.00         4\n",
            "          13       0.00      0.00      0.00         5\n",
            "          14       0.00      0.00      0.00         4\n",
            "          15       0.00      0.00      0.00         3\n",
            "          16       0.00      0.00      0.00         4\n",
            "          17       0.00      0.00      0.00         3\n",
            "          18       0.00      0.00      0.00         4\n",
            "          19       0.00      0.00      0.00         4\n",
            "          20       0.00      0.00      0.00         5\n",
            "          22       0.00      0.00      0.00         5\n",
            "          23       0.00      0.00      0.00         1\n",
            "          24       0.00      0.00      0.00         2\n",
            "          25       0.00      0.00      0.00         7\n",
            "          26       0.00      0.00      0.00         4\n",
            "          27       0.00      0.00      0.00         4\n",
            "          28       0.00      0.00      0.00         4\n",
            "          29       0.00      0.00      0.00         3\n",
            "          30       0.00      0.00      0.00         5\n",
            "          31       0.00      0.00      0.00         3\n",
            "          32       0.00      0.00      0.00         5\n",
            "          33       0.00      0.00      0.00         4\n",
            "          34       0.00      0.00      0.00         6\n",
            "          35       0.00      0.00      0.00         1\n",
            "          36       0.00      0.00      0.00         5\n",
            "          37       0.00      0.00      0.00         2\n",
            "          40       0.00      0.00      0.00         4\n",
            "          41       0.00      0.00      0.00         1\n",
            "          42       0.00      0.00      0.00         4\n",
            "          43       0.00      0.00      0.00         4\n",
            "          44       0.00      0.00      0.00         5\n",
            "          45       0.00      0.00      0.00         2\n",
            "          46       0.00      0.00      0.00         2\n",
            "          47       0.00      0.00      0.00         2\n",
            "          48       0.00      0.00      0.00         4\n",
            "          50       0.00      0.00      0.00         2\n",
            "          51       0.00      0.00      0.00         1\n",
            "          52       0.00      0.00      0.00         5\n",
            "          53       0.00      0.00      0.00         2\n",
            "          54       0.00      0.00      0.00         3\n",
            "          55       0.00      0.00      0.00         3\n",
            "          56       0.00      0.00      0.00         5\n",
            "          57       0.00      0.00      0.00         2\n",
            "          58       0.00      0.00      0.00         4\n",
            "          59       0.00      0.00      0.00         1\n",
            "          60       0.00      0.00      0.00         5\n",
            "          61       0.00      0.00      0.00         2\n",
            "          62       0.00      0.00      0.00         1\n",
            "          63       0.00      0.00      0.00         2\n",
            "          64       0.00      0.00      0.00         3\n",
            "          65       0.00      0.00      0.00         5\n",
            "          66       0.00      0.00      0.00         6\n",
            "          67       0.00      0.00      0.00         4\n",
            "          68       0.00      0.00      0.00         4\n",
            "          69       0.00      0.00      0.00         5\n",
            "          70       0.00      0.00      0.00         5\n",
            "          71       0.00      0.00      0.00         4\n",
            "          72       0.00      0.00      0.00         4\n",
            "          73       0.00      0.00      0.00         2\n",
            "          75       0.00      0.00      0.00         1\n",
            "          76       0.00      0.00      0.00         4\n",
            "          77       0.00      0.00      0.00         6\n",
            "          78       0.00      0.00      0.00         7\n",
            "          79       0.00      0.00      0.00         3\n",
            "          80       0.00      0.00      0.00         2\n",
            "          81       0.00      0.00      0.00         1\n",
            "          82       0.00      0.00      0.00         5\n",
            "          83       0.00      0.00      0.00         1\n",
            "          84       0.00      0.00      0.00         4\n",
            "          85       0.00      0.00      0.00         6\n",
            "          86       0.00      0.00      0.00         1\n",
            "          87       0.00      0.00      0.00         7\n",
            "          88       0.00      0.00      0.00         1\n",
            "          89       0.00      0.00      0.00         2\n",
            "          90       0.00      0.00      0.00         4\n",
            "          91       0.00      0.00      0.00         6\n",
            "          92       0.00      0.00      0.00         4\n",
            "          93       0.00      0.00      0.00         2\n",
            "          94       0.00      0.00      0.00         1\n",
            "          95       0.00      0.00      0.00         5\n",
            "          96       0.00      0.00      0.00         3\n",
            "          97       0.00      0.00      0.00         3\n",
            "          98       0.00      0.00      0.00         4\n",
            "          99       0.00      0.00      0.00         4\n",
            "         100       0.00      0.00      0.00         1\n",
            "         101       0.00      0.00      0.00         2\n",
            "         102       0.00      0.00      0.00         7\n",
            "         103       0.00      0.00      0.00         1\n",
            "         104       0.00      0.00      0.00         1\n",
            "         106       0.00      0.00      0.00         2\n",
            "         107       0.00      0.00      0.00         2\n",
            "         108       0.00      0.00      0.00         2\n",
            "         109       0.00      0.00      0.00         3\n",
            "         111       0.00      0.00      0.00         2\n",
            "         112       0.00      0.00      0.00         4\n",
            "         113       0.00      0.00      0.00         1\n",
            "         114       0.00      0.00      0.00         6\n",
            "         115       0.00      0.00      0.00         3\n",
            "         116       0.00      0.00      0.00         4\n",
            "         118       0.00      0.00      0.00         2\n",
            "         119       0.00      0.00      0.00         5\n",
            "         120       0.00      0.00      0.00         3\n",
            "         121       0.00      0.00      0.00         4\n",
            "         122       0.00      0.00      0.00         3\n",
            "         123       0.00      0.00      0.00         3\n",
            "         125       0.00      0.00      0.00         5\n",
            "         126       0.00      0.00      0.00         2\n",
            "         127       0.00      0.00      0.00         4\n",
            "         129       0.00      0.00      0.00         1\n",
            "         130       0.00      0.00      0.00         2\n",
            "         131       0.00      0.00      0.00         2\n",
            "         132       0.00      0.00      0.00         2\n",
            "         133       0.00      0.00      0.00         3\n",
            "         134       0.00      0.00      0.00         2\n",
            "         135       0.00      0.00      0.00         3\n",
            "         136       0.00      0.00      0.00         4\n",
            "         137       0.00      0.00      0.00         6\n",
            "         138       0.00      0.00      0.00         4\n",
            "         139       0.00      0.00      0.00         4\n",
            "         140       0.00      0.00      0.00         1\n",
            "         141       0.00      0.00      0.00         1\n",
            "         143       0.00      0.00      0.00         2\n",
            "         144       0.00      0.00      0.00         4\n",
            "         145       0.00      0.00      0.00         4\n",
            "         146       0.00      0.00      0.00         1\n",
            "         147       0.00      0.00      0.00         3\n",
            "         148       0.00      0.00      0.00         2\n",
            "         149       0.00      0.00      0.00         3\n",
            "         150       0.00      0.00      0.00         3\n",
            "         152       0.00      0.00      0.00         2\n",
            "         153       0.00      0.00      0.00         1\n",
            "         154       0.00      0.00      0.00         4\n",
            "         155       0.00      0.00      0.00         5\n",
            "         156       0.00      0.00      0.00         5\n",
            "         157       0.00      0.00      0.00         4\n",
            "         158       0.00      0.00      0.00         4\n",
            "         159       0.00      0.00      0.00         3\n",
            "         160       0.00      0.00      0.00         2\n",
            "         161       0.00      0.00      0.00         2\n",
            "         162       0.00      0.00      0.00         3\n",
            "         163       0.00      0.00      0.00         5\n",
            "         164       0.00      0.00      0.00         2\n",
            "         165       0.00      0.00      0.00         2\n",
            "         166       0.00      0.00      0.00         5\n",
            "         167       0.00      0.00      0.00         3\n",
            "         168       0.00      0.00      0.00         2\n",
            "         169       0.00      0.00      0.00         6\n",
            "         170       0.00      0.00      0.00         5\n",
            "         171       0.00      0.00      0.00         5\n",
            "         172       0.00      0.00      0.00         4\n",
            "         173       0.00      0.00      0.00         4\n",
            "         174       0.00      0.00      0.00         3\n",
            "         175       0.00      0.00      0.00         3\n",
            "         176       0.00      0.00      0.00         2\n",
            "         177       0.00      0.00      0.00         4\n",
            "         178       0.00      0.00      0.00         1\n",
            "         179       0.00      0.00      0.00         6\n",
            "         181       0.00      0.00      0.00         3\n",
            "         182       0.00      0.00      0.00         1\n",
            "         183       0.00      0.00      0.00         3\n",
            "         184       0.00      0.00      0.00         3\n",
            "         185       0.00      0.00      0.00         2\n",
            "         186       0.00      0.00      0.00         3\n",
            "         187       0.00      0.00      0.00         2\n",
            "         188       0.00      0.00      0.00         4\n",
            "         189       0.00      0.00      0.00         2\n",
            "         190       0.00      0.00      0.00         4\n",
            "         191       0.00      0.00      0.00         1\n",
            "         192       0.00      0.00      0.00         3\n",
            "\n",
            "    accuracy                           0.01       588\n",
            "   macro avg       0.00      0.01      0.00       588\n",
            "weighted avg       0.00      0.01      0.00       588\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n--- Classification Reports ---\")\n",
        "print(\"Logistic Regression:\\n\", classification_report(y_test, y_pred_lr))\n",
        "print(\"Naive Bayes:\\n\", classification_report(y_test, y_pred_nb))\n",
        "print(\"K-Nearest Neighbors:\\n\", classification_report(y_test, y_pred_knn))\n",
        "print(\"Decision Tree:\\n\", classification_report(y_test, y_pred_dt))\n",
        "print(\"Random Forest:\\n\", classification_report(y_test, y_pred_rf))\n",
        "print(\"KMeans (Clustering):\\n\", classification_report(y_test, y_pred_kmeans))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d5403d67-5569-4bca-ac2b-d02f7908b4ff",
      "metadata": {
        "id": "d5403d67-5569-4bca-ac2b-d02f7908b4ff"
      },
      "source": [
        "# Evaluate the performance using classification metrics.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dfe82154-1639-4b7a-9392-05b0b3aec073",
      "metadata": {
        "id": "dfe82154-1639-4b7a-9392-05b0b3aec073",
        "outputId": "f8a87489-1856-42e7-e296-74e58fe2fc83"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---Logistic Regression---\n",
            "Accuracy: 0.76\n",
            "Precision: 0.82\n",
            "Recall: 0.76\n",
            "F1 Score: 0.76\n",
            "Confusion Matrix:\n",
            "[[1 0 0 ... 0 0 0]\n",
            " [0 2 0 ... 0 0 0]\n",
            " [0 0 4 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 4 0 0]\n",
            " [0 0 0 ... 0 1 0]\n",
            " [0 0 0 ... 0 1 1]]\n",
            "----------------------------------------\n",
            "---Naive Bayes---\n",
            "Accuracy: 0.99\n",
            "Precision: 0.99\n",
            "Recall: 0.99\n",
            "F1 Score: 0.99\n",
            "Confusion Matrix:\n",
            "[[1 0 0 ... 0 0 0]\n",
            " [0 2 0 ... 0 0 0]\n",
            " [0 0 4 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 4 0 0]\n",
            " [0 0 0 ... 0 1 0]\n",
            " [0 0 0 ... 0 0 3]]\n",
            "----------------------------------------\n",
            "---K-Nearest Neighbors---\n",
            "Accuracy: 0.62\n",
            "Precision: 0.69\n",
            "Recall: 0.62\n",
            "F1 Score: 0.62\n",
            "Confusion Matrix:\n",
            "[[1 0 0 ... 0 0 0]\n",
            " [0 2 0 ... 0 0 0]\n",
            " [0 0 4 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 4 0 0]\n",
            " [0 0 0 ... 0 1 0]\n",
            " [0 0 0 ... 0 1 0]]\n",
            "----------------------------------------\n",
            "---Decision Tree---\n",
            "Accuracy: 0.98\n",
            "Precision: 0.98\n",
            "Recall: 0.98\n",
            "F1 Score: 0.97\n",
            "Confusion Matrix:\n",
            "[[1 0 0 ... 0 0 0]\n",
            " [0 2 0 ... 0 0 0]\n",
            " [0 0 4 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 4 0 0]\n",
            " [0 0 0 ... 0 1 0]\n",
            " [0 0 0 ... 0 0 3]]\n",
            "----------------------------------------\n",
            "---Random Forest---\n",
            "Accuracy: 0.99\n",
            "Precision: 0.99\n",
            "Recall: 0.99\n",
            "F1 Score: 0.99\n",
            "Confusion Matrix:\n",
            "[[1 0 0 ... 0 0 0]\n",
            " [0 2 0 ... 0 0 0]\n",
            " [0 0 4 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 4 0 0]\n",
            " [0 0 0 ... 0 1 0]\n",
            " [0 0 0 ... 0 0 3]]\n",
            "----------------------------------------\n",
            "---KMeans Clustering---\n",
            "Accuracy: 0.01\n",
            "Precision: 0.00\n",
            "Recall: 0.01\n",
            "F1 Score: 0.00\n",
            "Confusion Matrix:\n",
            "[[1 0 0 ... 0 0 0]\n",
            " [0 2 0 ... 0 0 0]\n",
            " [2 2 0 ... 0 0 0]\n",
            " ...\n",
            " [4 0 0 ... 0 0 0]\n",
            " [1 0 0 ... 0 0 0]\n",
            " [3 0 0 ... 0 0 0]]\n",
            "----------------------------------------\n"
          ]
        }
      ],
      "source": [
        "def evaluate_model(y_true, y_pred, model_name):\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred, average='weighted')\n",
        "    recall = recall_score(y_true, y_pred, average='weighted')\n",
        "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "    print(f'---{model_name}---')\n",
        "    print(f'Accuracy: {accuracy:.2f}')\n",
        "    print(f'Precision: {precision:.2f}')\n",
        "    print(f'Recall: {recall:.2f}')\n",
        "    print(f'F1 Score: {f1:.2f}')\n",
        "    print(f'Confusion Matrix:\\n{confusion_matrix(y_true, y_pred)}')\n",
        "    print('-'*40)\n",
        "\n",
        "# 1. Logistic Regression\n",
        "y_pred_lr = log_reg.predict(X_test)\n",
        "evaluate_model(y_test, y_pred_lr, \"Logistic Regression\")\n",
        "\n",
        "# 2. Naive Bayes\n",
        "y_pred_nb = nb_model.predict(X_test)\n",
        "evaluate_model(y_test, y_pred_nb, \"Naive Bayes\")\n",
        "\n",
        "# 3. K-Nearest Neighbors (KNN)\n",
        "y_pred_knn = knn.predict(X_test)\n",
        "evaluate_model(y_test, y_pred_knn, \"K-Nearest Neighbors\")\n",
        "\n",
        "# 4. Decision Tree\n",
        "y_pred_dt = dt_model.predict(X_test)\n",
        "evaluate_model(y_test, y_pred_dt, \"Decision Tree\")\n",
        "\n",
        "# 5. Random Forest\n",
        "y_pred_rf = rf_model.predict(X_test)\n",
        "evaluate_model(y_test, y_pred_rf, \"Random Forest\")\n",
        "\n",
        "# 6. KMeans (Clustering)\n",
        "y_pred_kmeans = np.where(kmeans.predict(X_test) == 0, 1, 0)\n",
        "evaluate_model(y_test, y_pred_kmeans, \"KMeans Clustering\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d4a66b2-8cde-4cc5-a5e7-14e23f2c6bc7",
      "metadata": {
        "id": "9d4a66b2-8cde-4cc5-a5e7-14e23f2c6bc7"
      },
      "source": [
        "#  Compare the performance of the entire classification algorithm (in table format having recall, precision, F1-score, accuracy))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b16e1fea-29ec-4f76-91b3-c0061f555f37",
      "metadata": {
        "id": "b16e1fea-29ec-4f76-91b3-c0061f555f37"
      },
      "outputs": [],
      "source": [
        "model_performance = {\n",
        "    \"Model\": [],\n",
        "    \"Accuracy\": [],\n",
        "    \"Precision\": [],\n",
        "    \"Recall\": [],\n",
        "    \"F1-Score\": []\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ef20d94-f5ac-45ce-849c-2c79a65e235d",
      "metadata": {
        "id": "9ef20d94-f5ac-45ce-849c-2c79a65e235d"
      },
      "outputs": [],
      "source": [
        "def evaluate_and_store_metrics(y_true, y_pred, model_name):\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred, average='weighted')\n",
        "    recall = recall_score(y_true, y_pred, average='weighted')\n",
        "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "\n",
        "    model_performance[\"Model\"].append(model_name)\n",
        "    model_performance[\"Accuracy\"].append(accuracy)\n",
        "    model_performance[\"Precision\"].append(precision)\n",
        "    model_performance[\"Recall\"].append(recall)\n",
        "    model_performance[\"F1-Score\"].append(f1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa8b27d0-4796-49c2-90a2-9cb777c7973b",
      "metadata": {
        "id": "fa8b27d0-4796-49c2-90a2-9cb777c7973b"
      },
      "outputs": [],
      "source": [
        "\n",
        "# 1. Logistic Regression\n",
        "y_pred_lr = log_reg.predict(X_test)\n",
        "evaluate_and_store_metrics(y_test, y_pred_lr, \"Logistic Regression\")\n",
        "\n",
        "# 2. Naive Bayes\n",
        "y_pred_nb = nb_model.predict(X_test)\n",
        "evaluate_and_store_metrics(y_test, y_pred_nb, \"Naive Bayes\")\n",
        "\n",
        "# 3. K-Nearest Neighbors (KNN)\n",
        "y_pred_knn = knn.predict(X_test)\n",
        "evaluate_and_store_metrics(y_test, y_pred_knn, \"K-Nearest Neighbors\")\n",
        "\n",
        "# 4. Decision Tree\n",
        "y_pred_dt = dt_model.predict(X_test)\n",
        "evaluate_and_store_metrics(y_test, y_pred_dt, \"Decision Tree\")\n",
        "\n",
        "# 5. Random Forest\n",
        "y_pred_rf = rf_model.predict(X_test)\n",
        "evaluate_and_store_metrics(y_test, y_pred_rf, \"Random Forest\")\n",
        "\n",
        "# 6. KMeans (Clustering)\n",
        "y_pred_kmeans = np.where(kmeans.predict(X_test) == 0, 1, 0)\n",
        "evaluate_and_store_metrics(y_test, y_pred_kmeans, \"KMeans Clustering\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ddfacb3-8d0e-46cf-b76a-94c2417743f5",
      "metadata": {
        "id": "9ddfacb3-8d0e-46cf-b76a-94c2417743f5",
        "outputId": "fe8b92c6-bf26-40f2-de54-5dc179b1b2cd"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1-Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Logistic Regression</td>\n",
              "      <td>0.755102</td>\n",
              "      <td>0.815873</td>\n",
              "      <td>0.755102</td>\n",
              "      <td>0.755959</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Naive Bayes</td>\n",
              "      <td>0.988095</td>\n",
              "      <td>0.986071</td>\n",
              "      <td>0.988095</td>\n",
              "      <td>0.985733</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>K-Nearest Neighbors</td>\n",
              "      <td>0.615646</td>\n",
              "      <td>0.690063</td>\n",
              "      <td>0.615646</td>\n",
              "      <td>0.619155</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Decision Tree</td>\n",
              "      <td>0.976190</td>\n",
              "      <td>0.978225</td>\n",
              "      <td>0.976190</td>\n",
              "      <td>0.974226</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Random Forest</td>\n",
              "      <td>0.994898</td>\n",
              "      <td>0.992687</td>\n",
              "      <td>0.994898</td>\n",
              "      <td>0.993445</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>KMeans Clustering</td>\n",
              "      <td>0.005102</td>\n",
              "      <td>0.000027</td>\n",
              "      <td>0.005102</td>\n",
              "      <td>0.000054</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 Model  Accuracy  Precision    Recall  F1-Score\n",
              "0  Logistic Regression  0.755102   0.815873  0.755102  0.755959\n",
              "1          Naive Bayes  0.988095   0.986071  0.988095  0.985733\n",
              "2  K-Nearest Neighbors  0.615646   0.690063  0.615646  0.619155\n",
              "3        Decision Tree  0.976190   0.978225  0.976190  0.974226\n",
              "4        Random Forest  0.994898   0.992687  0.994898  0.993445\n",
              "5    KMeans Clustering  0.005102   0.000027  0.005102  0.000054"
            ]
          },
          "execution_count": 109,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "performance_df = pd.DataFrame(model_performance)\n",
        "performance_df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a02c2da-6a8b-4e38-8656-05e542c4eb56",
      "metadata": {
        "id": "5a02c2da-6a8b-4e38-8656-05e542c4eb56"
      },
      "source": [
        "## Conclusion of this Mini Project :\n",
        "In this project, we applied various classification algorithms and evaluated their performance using accuracy, precision, recall, and F1-score. Random Forest performed best due to its ensemble nature, while simpler models like Logistic Regression and Naive Bayes were faster but less accurate. The choice of the best model depends on the dataset's complexity and the need for either performance or interpretability."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a622f755-8308-454b-a10e-6ef9143f388a",
      "metadata": {
        "id": "a622f755-8308-454b-a10e-6ef9143f388a"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}